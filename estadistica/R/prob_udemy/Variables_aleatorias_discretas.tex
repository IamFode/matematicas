% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Variables aleatorias discretas},
  pdfauthor={Christian Limbert Paredes Aguilera},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Variables aleatorias discretas}
\author{Christian Limbert Paredes Aguilera}
\date{1/12/2021}

\begin{document}
\maketitle

\hypertarget{definiciuxf3n-de-variable-aleatoria}{%
\subsection{Definición de variable
aleatoria}\label{definiciuxf3n-de-variable-aleatoria}}

Una variable aleatoria es una aplicación que toma valores numéricos
determinados por el resultado de un experimento aleatorio.

\hypertarget{tipos-de-variables-aleatorias}{%
\subsection{Tipos de variables
aleatorias}\label{tipos-de-variables-aleatorias}}

Variables aleatorias discretas, continua y mixtas.

\hypertarget{funciuxf3n-de-probabilidad-para-varibales-discretas}{%
\subsection{Función de probabilidad para varibales
discretas}\label{funciuxf3n-de-probabilidad-para-varibales-discretas}}

La función de probabilidad de una variable aleatoria discreta \(X\) es
la que denotamos por \[P_X(x) = P(X=x)\] Dominio de una variable
aleatoria discreta
\[D_X = \left\{ x \in \mathbb{R} \; | \, P_X(x) > 0\right\}\] en el caso
discreto lo mas habitual es que \[X(\Omega) =D_X\]

\hypertarget{propiedades-de-la-funciuxf3n-de-probabilidad}{%
\subsection{Propiedades de la función de
probabilidad}\label{propiedades-de-la-funciuxf3n-de-probabilidad}}

Sea \(X\) una v.a. discreta \(X:\Omega:\Rightarrow \mathbb{R}\) con
dominio \(D_X\). Su función de probabilidad \(P_X\) verifica las
siguientes propiedades:

\begin{itemize}
\item
  \(0\leq P_X(x) \leq 1\) para todo \(x\in \mathbb{R}\)
\item
  \(\sum\limits_{x\in D_X} P_X(x) = 1\)
\end{itemize}

\[P_X(x) = \left\{ \begin{array}{rcl} 
  \dfrac{1}{8} & si & x=0,3\\\\ 
  \dfrac{3}{8}& si & x=1,2\\\\
  0&&en\; otro \; caso\\\\
\end{array}\right.\]

Efectivamente los valores de la función de distribución suman 1
\[\sum_{x=0}^{3} P_X(x) = \dfrac{1}{8} + \dfrac{3}{8} + \dfrac{3}{8} + \dfrac{1}{8} = 1\]

\hypertarget{funciuxf3n-de-distribuciuxf3n-de-variables-aleatorias}{%
\subsection{Función de distribución de variables
aleatorias}\label{funciuxf3n-de-distribuciuxf3n-de-variables-aleatorias}}

La función de distribución de probabilidad (acumulada) de la v.a. X ya
sea discreta o continua \(F_X(x)\) representa la probabilidad de que
\(X\) toem un menor o igual que \(x\) es decir \[F_X(x) = P(X\leq x)\]
Sea \(X\) una v.a. y \(F_X\) su función de distribución

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(P(X>x) = 1-P(X\leq x) = 1 - F_X(x)\)
\end{enumerate}

Demostración.- Tenemos que el complementario de \(X\) mayor que \(x\) es
\(\overline{\lbrace X>x\rbrace} = \lbrace X>x\rbrace^c = \lbrace X\leq x\rbrace\).
Además

\[P(X>x) = 1 -P\left(\overline{\lbrace X > x}\rbrace\right) = 1 - P(X\leq x) = 1 - F_X(x)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Sea \(a\) y \(b\) tales que \(a<b\),
  \[P(a<X\leq b) = P(X\leq b) - P(X\leq a) = F_X(b) - F_X(a)\]
\end{enumerate}

Demostración.- Por otro lado, que \(X\) se encuentre entre dos valores
\(a\) y \(b\) es
\(\lbrace a<X\leq b \rbrace = \lbrace X\leq b \rbrace - \lbrace X\leq a \rbrace\)
ahora podemos hacer

\[\begin{array}{rcl}
  P(a<X\leq b)&=&P( \lbrace X\leq \lbrace - \lbrace X \leq a \rbrace )\\
  &=&P( \lbrace X \leq b \rbrace ) - P( \lbrace X \leq a \rbrace )\\
  &=&F_X(b)-F_X(a)\\
\end{array}\]

\hypertarget{propiedadades-de-la-funciuxf3n-de-distribuciuxf3n}{%
\subsubsection{propiedadades de la función de
distribución}\label{propiedadades-de-la-funciuxf3n-de-distribuciuxf3n}}

Sea \(F_X\) la función de distribución de un v.a. \(X\) entonces:

\begin{itemize}
\item $0\leq F_X(x) \leq 1$
\item La función $F_x$ es no decreciente.
\item Si denotamos por $F_X(x_o^-) = \displaystyle\lim_{x\to x_o^-} F(x)$, entonces se cumple que 

$P(X<x_0) = F_X(x_0^-)$ y que $P(X=x_0) = F_X(x_0) - F_X(x_0^-)$
\item Se cumple que $\displaystyle\lim_{x\to\infty} F_X(x)=1\;; \quad \lim_{x\to -\infty}F_X(x)=0$
\item Toda función $F$ verificando las propiedades anteriores es función de distribución de alguna v.a. $X$.
\item $P(X>x) = 1-F_X(x)$
\item Dado $a,b\in \mathbb{R}$ con $a < b$
$$P(a<X\leq b) = F_X(b) - F_X(a)$$
\end{itemize}

\hypertarget{desigualdades-estrictas}{%
\subsubsection{Desigualdades estrictas}\label{desigualdades-estrictas}}

\begin{itemize}
\item $P(X=x) = F_X(x)-F_X(x^-)$
\item $P(a<X<b) = F_X(b^-) - F_X(a)$
\item $P(a\leq X < b) = F_X(b^-) - F_X(a^-)$
\item $P(X<a)=F_X(a^-)$
\end{itemize}

\hypertarget{muxe1s-propiedades-de-la-funciuxf3n-de-distribuciuxf3n}{%
\subsubsection{Más propiedades de la función de
distribución}\label{muxe1s-propiedades-de-la-funciuxf3n-de-distribuciuxf3n}}

\begin{itemize}
\item Si $F_x$ es continua en $x$ se tiene que $P(X=x) = 0$ y por lo tanto $P(X\leq a) = P(X<a) + P(X=a) = P(X<a)$.

Demostración.- Si $X$ es continua entonces,
$$P(X=x) = F(a) - F(a^-) = F(a) - F(a) = 0$$
por lo tanto 
$$P(X\leq a) = P(X<a) + P(X=x) = P(X<a) + 0 = P(X<a)$$
\item Sea $X$ una v-a- discreta con dominio $D_X$ y que tiene por función de probabilidad $P_X(x)$ entonces su función de distribución $F_X(x_0)$ es 
$$F_X(x_0) = \sum_{x\leq x_0} P_X(x)$$
donde $\sum\limits_{x\leq x_0}$ indica que sumamos todos los $x\in D_X$ tales que $x\leq x_0$

Demostración.- 
$$F_X(x_0) = P(X\leq x_0) P\left(\bigcup_{x\leq x_0; x\in D_X} \lbrace x \rbrace \right) = \sum_{x\leq x_0}P(X=x)=  \sum_{x\leq x_0} P_X(x)$$
\end{itemize}

\hypertarget{valor-esperado}{%
\subsection{Valor esperado}\label{valor-esperado}}

\[E(X)=\sum_{x\in X(\Omega)} x P_X(x)\]

En ocasiones se le denomina media poblacional o simplemente media y muy
frecuentemente se la denota por
\[\mu_X = E(X) \quad o \quad \mu = E(X)\]

Si \({n\to \infty}\) se tiene que
\(\lim\limits_{n\to \infty} \dfrac{n_x}{x} = P_X(x)\) por lo tanto
\(E(X) = \lim\limits_{x\to \infty}\sum\limits_{x=1}^n x\dfrac{n_x}{n}\)
Entonces el valor esperado en una v.a. discreta puede entenderse como el
valor promedio que tomaría una v.a. en un número grande de repeticiones.

\hypertarget{esperanza-de-funciones-de-variables-aleatorias-discretas}{%
\subsubsection{Esperanza de funciones de variables aleatorias
discretas}\label{esperanza-de-funciones-de-variables-aleatorias-discretas}}

Sea \(X\) una v.a. discreta con función de probabilidad \(P_X\) y de
distribución \(F_X\). Entonces el valor esperado de una función \(f(x)\)
es: \[E(g(x)) = \sum_{x} g(x)P_X(x)\]

\hypertarget{propiedades-de-los-valores-esperados}{%
\subsubsection{Propiedades de los valores
esperados}\label{propiedades-de-los-valores-esperados}}

\begin{itemize}
\item $E(k) = k$ para cualquier constante $k$.

Demostración.- Se tiene que 
$$E(k) = \sum_{x=1}^n k\cdot P(X=k) = k\cdot P(X=k) + \ldots + k\cdot   P(X=k) = k\left[ P(X=k) + \ldots + P(X=k)\right] = k\cdot 1 = k$$

\item Si $a\leq X\leq b$ entonces $a\leq E(X) \leq b$

Demostración.- Sea $E(a) \leq E(X)\leq E(b)$ entonces por la anterior propiedad se tiene que $$a\leq E(X)\leq b$$

\item SI $X$ es una v.a. discreta que toma valores enteros no negativos entonces $E(X) = \sum\limits_{x=0}^{\infty} (1-F_X(x))$

Demostración.- Sea,
$$\begin{array}{rcl}
E(X)&=&\sum\limits_{k=0}^\infty k\cdot P(X=k)\\\\
&=&P(X=1)\\\\
&+&P(X=2)+P(X=2)\\\\
&+&P(X=3)+P(X=3)+P(X=3)\\\\
&+&P(X=4)+P(X=4)+P(X=4)+P(X=4)\\\\
&+&\ldots\\\\
\end{array}$$

Luego sumando por columnas se tiene,

$$\begin{array}{rcl}
\sum\limits_{k=1}^\infty P(X=k)&=&P(X>0)\\\\
\sum\limits_{k=2}^\infty P(X=k)&=&P(X>1)\\\\
\sum\limits_{k=3}^\infty P(X=k)&=&P(X>2)\\\\
\sum\limits_{x=0}^\infty kP(X=k)&=&\sum\limits_{k=0}^\infty P(X>k)\\\\
E(X)&=&\sum\limits_{k=0}^\infty 1-F_X(x)\\\\
\end{array}$$
\end{itemize}

\hypertarget{propiedades-de-las-series-geomuxe9tricas}{%
\subsubsection{Propiedades de las series
geométricas}\label{propiedades-de-las-series-geomuxe9tricas}}

\begin{itemize}
\item Una progresión geométrica de razon $r$ es una sucesión de la forma 
$$r^0,r^1,r^2, \ldots$$

\item La serie geométrica es la suma de todos los valores de la progresión geométrica
$$\sum_{k=0}^\infty r^k$$
\item Las sumas parciales desde el término $n_0$ al $n$ de una progesión geométrica valen
$$\sum_{k=n_0}^n r^k = \dfrac{r^{r_0}-r^n r}{1-r}$$
\item Si $|r|<1$ la serie geométrica es convergente y 
$$\sum_{k=0}^\infty r^k = \dfrac{1}{1-r}$$
\item En el caso en que se comience en $n_o$ se tiene que
$$\sum_{k=0}^\infty r^k = \dfrac{r^{n_0}}{1-r}$$
\item Si $|r|<1$ también son convergentes las derivadas, respecto de $f$, de la serie geométrica y convergen a la derivada correspondiente. Así teneos que 
$$\left(\sum_{k=0}^\infty r^k\right)^{'} = \sum_{k=1}^\infty kr^{k-1} \quad y \quad \left(\dfrac{1}{1-r}\right)^{'} = \dfrac{1}{(1-r)^2}$$
$$\left(\sum_{k=0}^\infty r^k\right)^{''} = \sum_{k=2}^\infty kr^{k-2}\quad y \quad \left(\dfrac{1}{1-r}\right)^{''} = \dfrac{2}{(1-r)^3}$$
\end{itemize}

Por lo tanto,

\[\begin{array}{rcl}
  E(X)&=&\sum\limits_{x=0}^\infty xP(X=x)\\\\
  &=&\sum\limits_{x=0}^\infty x\left(\dfrac{1}{2}\right)^{x+1}\\\\
  &=&\left(\dfrac{1}{2}\right)^2 \sum\limits_{x=0}^\infty x\left(\dfrac{1}{2}\right)^{x-1}\\\\  
  &=&\left(\dfrac{1}{2}\right)^2 \dfrac{1}{(1-\frac{1}{2})^2}\\\\
  &=&1\\\\
\end{array}\]

Luego calculamos su función de distrbución

\[\begin{array}{rcl}
  F_X(x)&=&P(X\leq x)\\\\
  &=&\sum\limits_{k=0}^x P(X=k)\\\\
  &=&\sum\limits_{k=0}^x \left(\dfrac{1}{2}\right)^{k+1}\\\\
  &=&\dfrac{\frac{1}{2}-\frac{1}{2}^{x+1} \frac{1}{2} }{1-\frac{1}{2} }\\\\
  &=&1-\left(\dfrac{1}{2}\right)^{x+1}\\\\
\end{array}\]

\hypertarget{momentos-de-orden-m}{%
\subsection{Momentos de orden m}\label{momentos-de-orden-m}}

LLamaremos momento de orden m respecto al punto \(C\) a
\[E\left[(X-C)^m\right] = \sum_{x\in X(\Omega)} (X-C)^m\cdot 
  P(x)\]

\begin{itemize}
  \item Cuando $C=0$ los momentos reciben el nombre de momentos respecto al origen.
  \item Cuando $C=E(x)$ reciben el nombre de momentos centrales o respecto de la media. Luego la esperanza es el momento de orden 1 respecto al origen. Estos momentos son la versión poblacional.
\end{itemize}

\hypertarget{varianza-y-desviaciuxf3n-tuxedpica}{%
\subsection{Varianza y desviación
típica}\label{varianza-y-desviaciuxf3n-tuxedpica}}

\hypertarget{la-varianza}{%
\subsubsection{La varianza}\label{la-varianza}}

Sea \(X\) una v.a. Llamaremos varianza de \(X\) a
\[Var(X) = E\left[(X-E(X))^2\right]\]

Por lo tanto la varianza es el momento central de orden 2.

de forma frecuente se utiliza la notación

\[\sigma_X^2 = Var(X)\]

A la raíz cuadrada positiva de la varianza

\[\sigma_X = \sqrt{Var(X)}\]

se la denomina desviación típica o estándar de \(X\).

\hypertarget{propiedades}{%
\subsubsection{Propiedades}\label{propiedades}}

\begin{itemize}
  \item Si $X$ es una v.a. discreta con función de probabilidad $P_X$ su varianza es
  $$\sigma_X^2 = Var(x) = E\left[(X-E(X))^2\right] = \sum_{x} \left[x-E(X)\right]P_X(x)$$
 
  \item Sea $X$ una v.a. 
  $$Var(X) = E(X^2) -\left[E(X)\right]^2 = \sum_{x} x^2 P_X(X) - \left[E(X)\right]^2$$
  
 Demostración.- 
 $$\begin{array}{rcl}
  Var(X)&=&\sum\limits_{x}\left[x-E(X)\right]^2P_X(x)\\\\
  &=&\sum\limits_{x}\left[x^2 - 2xE(X) + E(X)^2\right]P_X(x)\\\\
  &=&\sum\limits_{x} x^2P_X(x) - E(X)\sum\limits_{x}2xP_X(x) + E(X)^2 \sum\limits_{x}P_X(x)\\\\
  &=&E(X^2) - 2E(X)E(X) + E(X)^2\\\\
  &=&E(X^2) - E(X)^2\\\\
 \end{array}$$
 
\end{itemize}

\hypertarget{propiedades-de-la-varianza}{%
\subsubsection{Propiedades de la
varianza}\label{propiedades-de-la-varianza}}

\begin{itemize}   
  \item $Var(X) \geq 0$
    Demostración.- La definición nos dice que la diferencia de la v.a. X y la esperanza del mismo está elevada al cuadrado y por tanto $Var(X)\geq 0$.
    
  \item $Var(cte) = E(cte^2) -E(cte)^2 = cte^2 - cte^2 = 0$
    Demostración.- Dado que la varianza de una constante es la misma constante, entonces $cte^2 - cte^2$ y por tanto queda demostrada la proposición. 
    
  \item El mínimo de $E\left[(X-C)^2\right]$ se calcanza cuando $C=E(X)$ y es $Var(X)$. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.
    Demostración.- Sea
    $$\begin{array}{rcl}
      E\left[(X-C)^2\right]&=&\sum\limits_{x}(X-C)P_X(x)\\\\
      &=&\sum\limits_{Xx^2-2xC + C^2=P_X(x)\\\\
      &=&\sum\limits_{x}x^2P(X) - 2\sum\limits_{x} XCP_X(x) + \sum\limits_{x}C^2P_X(x)\\\\
      &=&\sum\limits_{x}X^2P(x)-2CE(x) + C^2\\\\
    \end{array}$$
    
  Luego derivando e igualando a cero nos queda
  $2E(x)-2C = 0$ y por lo tanto $C=E(X)$
  
  por último para minimizar necesitamos saber que la no convexidad va hacia arriba realizando su segunda derivada, de donde concluimos que efectivamente se está minimizando.
    
\end{itemize}

\end{document}
